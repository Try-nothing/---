{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed5fa9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from transformers import AutoTokenizer, EsmForTokenClassification, TrainingArguments\n",
    "import torch\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import EsmForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9397417",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = pickle.load(open('WSAA_data_public.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec61b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设datas是包含序列和标签的列表（格式见问题中的pickle数据）\n",
    "sequences = [data['sequence'] for data in datas]\n",
    "labels = [data['label'].squeeze().tolist() for data in datas]  # 确保标签是List[int]\n",
    "\n",
    "# 转换为Hugging Face Dataset\n",
    "dataset = Dataset.from_dict({\n",
    "    \"sequence\": sequences,\n",
    "    \"labels\": labels\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c752f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载快速分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t30_150M_UR50D\", use_fast=True)\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    # 对序列进行分词（非快速分词器）\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"sequence\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=2048,\n",
    "        return_tensors=\"pt\",\n",
    "        add_special_tokens=True  # 包含[CLS]和[SEP]\n",
    "    )\n",
    "    \n",
    "    labels = []\n",
    "    for i, (sequence, label) in enumerate(zip(examples[\"sequence\"], examples[\"labels\"])):\n",
    "        # 获取分词后的tokens（包括特殊token）\n",
    "        tokens = tokenizer.convert_ids_to_tokens(tokenized_inputs[\"input_ids\"][i])\n",
    "        \n",
    "        # 初始化对齐后的标签列表\n",
    "        aligned_labels = []\n",
    "        seq_pos = 0  # 原始序列中的位置\n",
    "        \n",
    "        for token in tokens:\n",
    "            if token in [tokenizer.cls_token, tokenizer.sep_token, tokenizer.pad_token]:\n",
    "                # 特殊token对应标签设为-100（被忽略）\n",
    "                aligned_labels.append(-100)\n",
    "            elif token.startswith(\"<\") or token.endswith(\">\"):  # 其他特殊token\n",
    "                aligned_labels.append(-100)\n",
    "            else:\n",
    "                # 确保token与原始序列中的氨基酸匹配\n",
    "                if seq_pos < len(sequence) and token == sequence[seq_pos]:\n",
    "                    aligned_labels.append(label[seq_pos])\n",
    "                    seq_pos += 1\n",
    "                else:\n",
    "                    # 处理分词意外情况（如未知token）\n",
    "                    aligned_labels.append(-100)\n",
    "        \n",
    "        labels.append(aligned_labels)\n",
    "    \n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caf2236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # 移除忽略的标签（-100）\n",
    "    true_labels = [[l for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [p for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    # 展平列表\n",
    "    true_labels_flat = np.concatenate(true_labels)\n",
    "    true_predictions_flat = np.concatenate(true_predictions)\n",
    "\n",
    "    # 计算分类报告\n",
    "    report = classification_report(\n",
    "        true_labels_flat,\n",
    "        true_predictions_flat,\n",
    "        target_names=[\"Not Binding Site\", \"Binding Site\"],\n",
    "        output_dict=True,\n",
    "    )\n",
    "    return {\"precision\": report[\"weighted avg\"][\"precision\"], \n",
    "            \"recall\": report[\"weighted avg\"][\"recall\"], \n",
    "            \"f1\": report[\"weighted avg\"][\"f1-score\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62c3c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1743/1743 [00:08<00:00, 214.46 examples/s]\n",
      "Map: 100%|██████████| 436/436 [00:02<00:00, 214.65 examples/s]\n",
      "Some weights of EsmForTokenClassification were not initialized from the model checkpoint at raw_model\\esm2-8M and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1308' max='1308' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1308/1308 25:05, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.434600</td>\n",
       "      <td>0.409609</td>\n",
       "      <td>0.795558</td>\n",
       "      <td>0.813218</td>\n",
       "      <td>0.767450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.405400</td>\n",
       "      <td>0.394113</td>\n",
       "      <td>0.816039</td>\n",
       "      <td>0.832138</td>\n",
       "      <td>0.812988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.304100</td>\n",
       "      <td>0.405673</td>\n",
       "      <td>0.817183</td>\n",
       "      <td>0.830242</td>\n",
       "      <td>0.800623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.303800</td>\n",
       "      <td>0.411733</td>\n",
       "      <td>0.820405</td>\n",
       "      <td>0.827957</td>\n",
       "      <td>0.790986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.418300</td>\n",
       "      <td>0.395063</td>\n",
       "      <td>0.819757</td>\n",
       "      <td>0.831558</td>\n",
       "      <td>0.801721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.501900</td>\n",
       "      <td>0.384381</td>\n",
       "      <td>0.825806</td>\n",
       "      <td>0.839565</td>\n",
       "      <td>0.824484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.376400</td>\n",
       "      <td>0.390696</td>\n",
       "      <td>0.821403</td>\n",
       "      <td>0.836112</td>\n",
       "      <td>0.817218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.288800</td>\n",
       "      <td>0.402979</td>\n",
       "      <td>0.820523</td>\n",
       "      <td>0.833627</td>\n",
       "      <td>0.807501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.345800</td>\n",
       "      <td>0.402835</td>\n",
       "      <td>0.822604</td>\n",
       "      <td>0.835830</td>\n",
       "      <td>0.812155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.321300</td>\n",
       "      <td>0.396853</td>\n",
       "      <td>0.820198</td>\n",
       "      <td>0.834623</td>\n",
       "      <td>0.812172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.336800</td>\n",
       "      <td>0.388450</td>\n",
       "      <td>0.824478</td>\n",
       "      <td>0.838281</td>\n",
       "      <td>0.824665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.382500</td>\n",
       "      <td>0.395761</td>\n",
       "      <td>0.817947</td>\n",
       "      <td>0.833416</td>\n",
       "      <td>0.812758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.309300</td>\n",
       "      <td>0.395381</td>\n",
       "      <td>0.818127</td>\n",
       "      <td>0.833641</td>\n",
       "      <td>0.813878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1743/1743 [00:08<00:00, 206.74 examples/s]\n",
      "Map: 100%|██████████| 436/436 [00:02<00:00, 214.32 examples/s]\n",
      "Some weights of EsmForTokenClassification were not initialized from the model checkpoint at raw_model\\esm2-8M and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1308' max='1308' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1308/1308 19:09, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.429300</td>\n",
       "      <td>0.404795</td>\n",
       "      <td>0.781226</td>\n",
       "      <td>0.801580</td>\n",
       "      <td>0.722070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.338600</td>\n",
       "      <td>0.391171</td>\n",
       "      <td>0.806455</td>\n",
       "      <td>0.826875</td>\n",
       "      <td>0.804727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.386100</td>\n",
       "      <td>0.392269</td>\n",
       "      <td>0.811245</td>\n",
       "      <td>0.810677</td>\n",
       "      <td>0.810958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.323800</td>\n",
       "      <td>0.395321</td>\n",
       "      <td>0.805392</td>\n",
       "      <td>0.823665</td>\n",
       "      <td>0.808828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.324000</td>\n",
       "      <td>0.396433</td>\n",
       "      <td>0.812825</td>\n",
       "      <td>0.831390</td>\n",
       "      <td>0.808068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.306700</td>\n",
       "      <td>0.408987</td>\n",
       "      <td>0.807340</td>\n",
       "      <td>0.827547</td>\n",
       "      <td>0.801434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.289700</td>\n",
       "      <td>0.392636</td>\n",
       "      <td>0.812232</td>\n",
       "      <td>0.830550</td>\n",
       "      <td>0.812474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.326900</td>\n",
       "      <td>0.390841</td>\n",
       "      <td>0.811407</td>\n",
       "      <td>0.829912</td>\n",
       "      <td>0.811805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.378300</td>\n",
       "      <td>0.389199</td>\n",
       "      <td>0.808771</td>\n",
       "      <td>0.826064</td>\n",
       "      <td>0.812105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.334400</td>\n",
       "      <td>0.400778</td>\n",
       "      <td>0.812444</td>\n",
       "      <td>0.831088</td>\n",
       "      <td>0.810572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.378400</td>\n",
       "      <td>0.399898</td>\n",
       "      <td>0.811156</td>\n",
       "      <td>0.829802</td>\n",
       "      <td>0.811326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.280500</td>\n",
       "      <td>0.405448</td>\n",
       "      <td>0.812948</td>\n",
       "      <td>0.831510</td>\n",
       "      <td>0.809898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.303700</td>\n",
       "      <td>0.399004</td>\n",
       "      <td>0.811171</td>\n",
       "      <td>0.829701</td>\n",
       "      <td>0.811698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1743/1743 [00:08<00:00, 205.94 examples/s]\n",
      "Map: 100%|██████████| 436/436 [00:02<00:00, 212.32 examples/s]\n",
      "Some weights of EsmForTokenClassification were not initialized from the model checkpoint at raw_model\\esm2-8M and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1308' max='1308' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1308/1308 23:22, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.427900</td>\n",
       "      <td>0.388740</td>\n",
       "      <td>0.816434</td>\n",
       "      <td>0.830118</td>\n",
       "      <td>0.770028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.375255</td>\n",
       "      <td>0.831739</td>\n",
       "      <td>0.846875</td>\n",
       "      <td>0.813109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.376600</td>\n",
       "      <td>0.371507</td>\n",
       "      <td>0.834234</td>\n",
       "      <td>0.851660</td>\n",
       "      <td>0.831570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.297300</td>\n",
       "      <td>0.363591</td>\n",
       "      <td>0.838908</td>\n",
       "      <td>0.854189</td>\n",
       "      <td>0.830291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.318100</td>\n",
       "      <td>0.368663</td>\n",
       "      <td>0.837292</td>\n",
       "      <td>0.853456</td>\n",
       "      <td>0.830743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.324000</td>\n",
       "      <td>0.361445</td>\n",
       "      <td>0.839793</td>\n",
       "      <td>0.853529</td>\n",
       "      <td>0.842788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.297800</td>\n",
       "      <td>0.359627</td>\n",
       "      <td>0.837640</td>\n",
       "      <td>0.853898</td>\n",
       "      <td>0.837354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.347900</td>\n",
       "      <td>0.361213</td>\n",
       "      <td>0.836761</td>\n",
       "      <td>0.849860</td>\n",
       "      <td>0.840444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.277000</td>\n",
       "      <td>0.365044</td>\n",
       "      <td>0.837036</td>\n",
       "      <td>0.853602</td>\n",
       "      <td>0.835632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.392800</td>\n",
       "      <td>0.365563</td>\n",
       "      <td>0.838466</td>\n",
       "      <td>0.852029</td>\n",
       "      <td>0.841779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.342800</td>\n",
       "      <td>0.360481</td>\n",
       "      <td>0.838901</td>\n",
       "      <td>0.851782</td>\n",
       "      <td>0.842396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.358300</td>\n",
       "      <td>0.361889</td>\n",
       "      <td>0.838183</td>\n",
       "      <td>0.852786</td>\n",
       "      <td>0.840899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.384200</td>\n",
       "      <td>0.360388</td>\n",
       "      <td>0.838303</td>\n",
       "      <td>0.853359</td>\n",
       "      <td>0.840505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1743/1743 [00:08<00:00, 203.36 examples/s]\n",
      "Map: 100%|██████████| 436/436 [00:02<00:00, 211.83 examples/s]\n",
      "Some weights of EsmForTokenClassification were not initialized from the model checkpoint at raw_model\\esm2-8M and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1308' max='1308' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1308/1308 30:43, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.548200</td>\n",
       "      <td>0.394245</td>\n",
       "      <td>0.842517</td>\n",
       "      <td>0.840923</td>\n",
       "      <td>0.788476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.398100</td>\n",
       "      <td>0.389629</td>\n",
       "      <td>0.832181</td>\n",
       "      <td>0.823005</td>\n",
       "      <td>0.827104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.332700</td>\n",
       "      <td>0.357205</td>\n",
       "      <td>0.842468</td>\n",
       "      <td>0.856898</td>\n",
       "      <td>0.832465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.413100</td>\n",
       "      <td>0.351372</td>\n",
       "      <td>0.839412</td>\n",
       "      <td>0.855550</td>\n",
       "      <td>0.839842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.333700</td>\n",
       "      <td>0.349768</td>\n",
       "      <td>0.844518</td>\n",
       "      <td>0.858979</td>\n",
       "      <td>0.837404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.363700</td>\n",
       "      <td>0.348985</td>\n",
       "      <td>0.844930</td>\n",
       "      <td>0.859533</td>\n",
       "      <td>0.839244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.306800</td>\n",
       "      <td>0.349128</td>\n",
       "      <td>0.844988</td>\n",
       "      <td>0.859518</td>\n",
       "      <td>0.838965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.285900</td>\n",
       "      <td>0.350467</td>\n",
       "      <td>0.840044</td>\n",
       "      <td>0.856181</td>\n",
       "      <td>0.839670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.344900</td>\n",
       "      <td>0.350187</td>\n",
       "      <td>0.839353</td>\n",
       "      <td>0.855412</td>\n",
       "      <td>0.840098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.377100</td>\n",
       "      <td>0.355796</td>\n",
       "      <td>0.836257</td>\n",
       "      <td>0.847445</td>\n",
       "      <td>0.840207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.299100</td>\n",
       "      <td>0.351978</td>\n",
       "      <td>0.839175</td>\n",
       "      <td>0.855316</td>\n",
       "      <td>0.839821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.285500</td>\n",
       "      <td>0.351843</td>\n",
       "      <td>0.836432</td>\n",
       "      <td>0.850360</td>\n",
       "      <td>0.840183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>0.351437</td>\n",
       "      <td>0.836576</td>\n",
       "      <td>0.851327</td>\n",
       "      <td>0.839979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1744/1744 [00:08<00:00, 204.67 examples/s]\n",
      "Map: 100%|██████████| 435/435 [00:02<00:00, 210.05 examples/s]\n",
      "Some weights of EsmForTokenClassification were not initialized from the model checkpoint at raw_model\\esm2-8M and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1308' max='1308' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1308/1308 31:42, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.385100</td>\n",
       "      <td>0.407397</td>\n",
       "      <td>0.772371</td>\n",
       "      <td>0.808622</td>\n",
       "      <td>0.759065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.361800</td>\n",
       "      <td>0.399124</td>\n",
       "      <td>0.805138</td>\n",
       "      <td>0.826971</td>\n",
       "      <td>0.801262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.328000</td>\n",
       "      <td>0.395043</td>\n",
       "      <td>0.816108</td>\n",
       "      <td>0.832895</td>\n",
       "      <td>0.802286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.417200</td>\n",
       "      <td>0.386223</td>\n",
       "      <td>0.822529</td>\n",
       "      <td>0.838157</td>\n",
       "      <td>0.824176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.350600</td>\n",
       "      <td>0.391993</td>\n",
       "      <td>0.818427</td>\n",
       "      <td>0.828385</td>\n",
       "      <td>0.822177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.308500</td>\n",
       "      <td>0.391644</td>\n",
       "      <td>0.817845</td>\n",
       "      <td>0.835592</td>\n",
       "      <td>0.812372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.321100</td>\n",
       "      <td>0.387164</td>\n",
       "      <td>0.825204</td>\n",
       "      <td>0.840770</td>\n",
       "      <td>0.819045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.310400</td>\n",
       "      <td>0.395529</td>\n",
       "      <td>0.819487</td>\n",
       "      <td>0.834880</td>\n",
       "      <td>0.822364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.318800</td>\n",
       "      <td>0.397021</td>\n",
       "      <td>0.821931</td>\n",
       "      <td>0.838517</td>\n",
       "      <td>0.816647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.364100</td>\n",
       "      <td>0.391047</td>\n",
       "      <td>0.822904</td>\n",
       "      <td>0.838786</td>\n",
       "      <td>0.823838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.285300</td>\n",
       "      <td>0.391152</td>\n",
       "      <td>0.821203</td>\n",
       "      <td>0.836513</td>\n",
       "      <td>0.823719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.391600</td>\n",
       "      <td>0.394997</td>\n",
       "      <td>0.821304</td>\n",
       "      <td>0.837508</td>\n",
       "      <td>0.822455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.380700</td>\n",
       "      <td>0.392456</td>\n",
       "      <td>0.820637</td>\n",
       "      <td>0.836543</td>\n",
       "      <td>0.822625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=114514)\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(dataset)):\n",
    "    # 清除之前的显存\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    train_dataset = dataset.select(train_index)\n",
    "    val_dataset = dataset.select(val_index)\n",
    "    \n",
    "    # 应用处理\n",
    "    tokenized_train_dataset = train_dataset.map(\n",
    "        tokenize_and_align_labels,\n",
    "        batched=True,\n",
    "        remove_columns=train_dataset.column_names,\n",
    "        num_proc=4\n",
    "    )\n",
    "\n",
    "    tokenized_val_dataset = val_dataset.map(\n",
    "        tokenize_and_align_labels,\n",
    "        batched=True,\n",
    "        remove_columns=val_dataset.column_names,\n",
    "        num_proc=4\n",
    "    )\n",
    "\n",
    "    model = EsmForTokenClassification.from_pretrained(\n",
    "        \"facebook/esm2_t30_150M_UR50D\",\n",
    "        num_labels=2,  # 二分类\n",
    "        id2label={0: 0, 1: 1},\n",
    "        label2id={0: 0, 1: 1},\n",
    "        ignore_mismatched_sizes=True,  # 忽略预训练头与当前头的尺寸不匹配\n",
    "    )\n",
    "\n",
    "    # model = get_peft_model(model, lora_config)\n",
    "    # model.print_trainable_parameters()\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f'finetuned_model/esm2-150M-L3000/cross_valid/logging/fold_{fold+1}',\n",
    "        per_device_train_batch_size=4,\n",
    "        gradient_accumulation_steps=3,\n",
    "        # eval_accumulation_steps=3,\n",
    "        per_device_eval_batch_size=8,\n",
    "        # 手动设置评估和保存频率（替代 evaluation_strategy 和 save_strategy）\n",
    "        eval_steps=100,  # 每100步评估一次\n",
    "        save_steps=100,  # 每100步保存一次\n",
    "        logging_dir=\"./logs\",\n",
    "        logging_steps=50,\n",
    "        num_train_epochs=6,\n",
    "        learning_rate=2e-5,\n",
    "        weight_decay=0.01,\n",
    "        fp16=True,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        # save_strategy=\"steps\",\n",
    "        eval_strategy='steps',\n",
    "        dataloader_num_workers=8,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train_dataset,\n",
    "        eval_dataset=tokenized_val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # 保存模型\n",
    "    model.save_pretrained(f'finetuned_model/esm2-150M-L3000/cross_valid/fold_{fold+1}', max_shard_size=\"196MB\", safe_serialization=True)\n",
    "    tokenizer.save_pretrained(f'finetuned_model/esm2-150M-L3000/cross_valid/fold_{fold+1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e6e5945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = pipeline(\n",
    "#     \"token-classification\",\n",
    "#     model='finetuned_model/esm2-8M/lora_finetune',\n",
    "#     tokenizer='finetuned_model/esm2-8M/lora_finetune',\n",
    "#     device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e78ee01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_gt, total_pred = [], []\n",
    "\n",
    "# for idx in range(len(dataset['test'])):\n",
    "#     seq = dataset['test'][idx]['sequence']\n",
    "#     label = dataset['test'][idx]['labels']\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         outputs = classifier(seq)\n",
    "    \n",
    "#     seq_res = []\n",
    "#     for out in outputs:\n",
    "#         if out['entity'] == 'LABEL_0':\n",
    "#             seq_res.append(0)\n",
    "#         else:\n",
    "#             seq_res.append(1)\n",
    "\n",
    "#     total_gt.extend(label)\n",
    "#     total_pred.extend(seq_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7645789d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(total_gt, total_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
